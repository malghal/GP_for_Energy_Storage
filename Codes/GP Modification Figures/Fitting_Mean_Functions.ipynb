{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d30e2f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpcam import GPOptimizer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d315383",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "063ca2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5546, 9477, 2231, 4437, 7059, 5259, 8330, 1068, 8214, 5888, 3275, 6845, 7671, 299, 5038, 3503, 8673, 2236, 3644, 4980, 993, 7545, 654, 1418, 6090, 7936, 8792, 6910, 2933, 2382, 9730, 8476, 1882, 7986, 7091, 4813, 3086, 3908, 1539, 8567, 2152, 5738, 8646, 9692, 2661, 6766, 7230, 512, 758, 2881]\n",
      "max y:  529.5870098158235\n",
      "x data:  (2500, 1)\n",
      "y data:  (2500, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fac7ff4c5e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_data = np.load(\"/data/Synthetic Data Generation_1/my_synthetic_energy.npy\")\n",
    "cycle_number = np.load(\"/data/Synthetic Data Generation_1/my_synthetic_cycleNum.npy\")\n",
    "\n",
    "\n",
    "\n",
    "label_size = 30\n",
    "\n",
    "num_of_datasets = 50\n",
    "\n",
    "considered_batteries = ([5546, 9477, 2231, 4437, 7059, 5259, 8330, 1068, 8214, 5888, 3275, 6845, 7671, \n",
    "                         299, 5038, 3503, 8673, 2236, 3644, 4980, 993, 7545, 654, 1418, 6090, 7936, 8792, \n",
    "                         6910, 2933, 2382, 9730, 8476, 1882, 7986, 7091, 4813, 3086, 3908, 1539, 8567, 2152, \n",
    "                         5738, 8646, 9692, 2661, 6766, 7230, 512, 758, 2881])\n",
    "\n",
    "\n",
    "print(considered_batteries)\n",
    "\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "for i in considered_batteries: plt.scatter(cycle_number,energy_data[int(i)])\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=label_size) # Set the font size of the tick labels on the x and y axes\n",
    "plt.xlabel(\"Cycle Number\",fontsize=label_size)\n",
    "plt.ylabel(\"Quantity of Interest\",fontsize=label_size)\n",
    "plt.show()\n",
    "\n",
    "print(\"max y: \", np.max(energy_data))\n",
    "\n",
    "# Initializing the data to fit the GP model\n",
    "data_size = num_of_datasets\n",
    "\n",
    "# All Data\n",
    "x_data = np.tile(cycle_number, data_size).reshape(-1, 1) # repeat cycle 20 times to create x_data\n",
    "y_data = np.vstack(energy_data[considered_batteries, :].T).reshape(-1, 1)\n",
    "x_pred = np.linspace(0,1000,1001).reshape(-1,1)\n",
    "\n",
    "\n",
    "print(\"x data: \", x_data.shape)\n",
    "print(\"y data: \", y_data.shape)\n",
    "        \n",
    "    \n",
    "plt.scatter(x_data,y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f8e5a-8fc3-4fd6-86bc-36719a9d63b5",
   "metadata": {},
   "source": [
    "# Creating the Subfolder in Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e44749d2-79b2-41cc-aacd-053131033518",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m new_folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/results/Methods Figures\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create the folder\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mmakedirs(new_folder_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify the path for the new folder\n",
    "new_folder_path = f\"/results/Methods Figures\"\n",
    "\n",
    "# Create the folder\n",
    "os.makedirs(new_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c0676a",
   "metadata": {},
   "source": [
    "# 1 - Power-law Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6b892a",
   "metadata": {},
   "source": [
    "## GP Components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a5da81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(x1,x2):\n",
    "    d = np.zeros((len(x1),len(x2)))\n",
    "    for i in range(x1.shape[1]):\n",
    "        d += (x1[:,i].reshape(-1, 1) - x2[:,i])**2\n",
    "    return np.sqrt(d)\n",
    "\n",
    "# For the Noise\n",
    "def s(x, my_slope, my_pow, my_intercept):\n",
    "    o = my_slope * (x**my_pow) + my_intercept\n",
    "    return o\n",
    "\n",
    "\n",
    "def my_noise(x,hps,obj):\n",
    "\n",
    "    my_slope     = hps[2]\n",
    "    my_pow       = hps[3]\n",
    "    my_intercept = hps[4]\n",
    "    \n",
    "    noise = np.identity(len(x)) * s(x,my_slope,my_pow,my_intercept)\n",
    "\n",
    "    return noise\n",
    "\n",
    "def kernel(x1,x2,hps,obj):\n",
    "    d = get_distance_matrix(x1,x2) \n",
    "    k = hps[0] * obj.squared_exponential_kernel(d,hps[1])\n",
    "    return k\n",
    "\n",
    "\n",
    "def mean(x,hps,obj):\n",
    "    return -( hps[5] * x[:,0])**2 + hps[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8053d40e",
   "metadata": {},
   "source": [
    "## GP Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82cac6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the GP Model\n",
    "init_hyperparameters = np.array( [3.23032552e+01, 1.67736159e+02, 1.93296950e-05, 2.59001100e+00,\n",
    " 2.88176470e+00, 1.23187950e-02, 4.99961417e+02])\n",
    "\n",
    "my_gp = GPOptimizer(x_data,y_data,\n",
    "            init_hyperparameters = init_hyperparameters,  # we need enough of those for kernel, noise and prior mean functions\n",
    "            compute_device='cpu', \n",
    "            gp_kernel_function=kernel,\n",
    "            gp_kernel_function_grad=None, \n",
    "            gp_mean_function=mean, \n",
    "            gp_mean_function_grad=None,\n",
    "            gp_noise_function=my_noise,\n",
    "            normalize_y=False,\n",
    "            sparse_mode=False,\n",
    "            gp2Scale = False,\n",
    "            store_inv=False, \n",
    "            ram_economy=False, \n",
    "            args=None)\n",
    "\n",
    "# Setting the Optimization Bounds for Hyperparameters\n",
    "bounds = np.empty((7,2))\n",
    "\n",
    "# Kernel Sq Exp\n",
    "bounds[0] = np.array([1e-5,6000.])                     # Kernel Variance\n",
    "bounds[1] = np.array([100.,1000.])                     # Kernel Lengthscale\n",
    "\n",
    "# Noise\n",
    "bounds[2] = np.array([1e-10,1.])                       # Noise Slope\n",
    "bounds[3] = np.array([2,5.])                           # Noise Power\n",
    "bounds[4] = np.array([0.,6.])                          # Noise Intercept\n",
    "# Mean\n",
    "bounds[5] = np.array([1e-5,100.])                      # Mean slope\n",
    "bounds[6] = np.array([400.,600.])                       # Mean intercept\n",
    "\n",
    "#my_gp.train(hyperparameter_bounds=bounds,max_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f543731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"hps: \", my_gpo.hyperparameters)\n",
    "f = my_gp.posterior_mean(x_pred)[\"f(x)\"]\n",
    "v = my_gp.posterior_covariance(x_pred)[\"v(x)\"]\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(x_pred[:,0],f, color = \"blue\", linewidth = 3, label = str(data_size) + \" cells\")\n",
    "plt.scatter(x_data[:,0],y_data, color = \"black\") # Training Data\n",
    "plt.fill_between(x_pred[:,0],f - 2. * np.sqrt(v), f + 2. * np.sqrt(v), alpha = 0.5, color = \"grey\")\n",
    "plt.xlabel(\"cycle number\") \n",
    "plt.ylabel(\"energy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0df6d",
   "metadata": {},
   "source": [
    "## Plotting the Prior Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce1db2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"hps: \", my_gp.hyperparameters)\n",
    "\n",
    "trained_hps = np.array( [3.23032552e+01, 1.67736159e+02, 1.93296950e-05, 2.59001100e+00,\n",
    " 2.88176470e+00, 1.23187950e-02, 4.99961417e+02])\n",
    "\n",
    "\n",
    "#trained_prior_y = mean(x_pred,my_gp.hyperparameters,2)\n",
    "\n",
    "trained_prior_y_powerlaw = mean(x_pred,trained_hps,2)\n",
    "\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize = (15,10))\n",
    "#plt.plot(x_pred[:,0],prior_y, color = \"red\", linewidth = 6, label = \"Trained Prior\")\n",
    "plt.plot(x_pred[:,0],trained_prior_y_powerlaw, color = \"red\", linewidth = 6, label = \"Trained Prior Mean\")\n",
    "plt.scatter(x_data[:,0],y_data, color = \"black\",label = \"Synthetic Data\") # All Data\n",
    "plt.tick_params(axis='both', which='major', labelsize=label_size) # Set the font size of the tick labels on the x and y axes\n",
    "plt.xlabel(\"Cycle Number\",fontsize=label_size) \n",
    "plt.ylabel(\"Quantity of Interest\",fontsize=label_size)\n",
    "plt.legend(fontsize=label_size,frameon=False)\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig(\"/results/Methods Figures/Power Law Model.png\", dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d9a0a",
   "metadata": {},
   "source": [
    "#  2 - Two-Element Piecewise Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5644e",
   "metadata": {},
   "source": [
    "## GP Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "193738f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(x1,x2):\n",
    "    d = np.zeros((len(x1),len(x2)))\n",
    "    for i in range(x1.shape[1]):\n",
    "        d += (x1[:,i].reshape(-1, 1) - x2[:,i])**2\n",
    "    return np.sqrt(d)\n",
    "\n",
    "\n",
    "# For the Noise\n",
    "def s(x, my_slope, my_pow, my_intercept):\n",
    "    o = my_slope * (x**my_pow) + my_intercept\n",
    "    return o\n",
    "\n",
    "\n",
    "def my_noise(x,hps,obj):\n",
    "\n",
    "    my_slope     = hps[2]\n",
    "    my_pow       = hps[3]\n",
    "    my_intercept = hps[4]\n",
    "    \n",
    "    noise = np.identity(len(x)) * s(x,my_slope,my_pow,my_intercept)\n",
    "\n",
    "    return noise\n",
    "\n",
    "def kernel(x1,x2,hps,obj):\n",
    "    d = get_distance_matrix(x1,x2) \n",
    "    k = hps[0] * obj.squared_exponential_kernel(d,hps[1])\n",
    "    return k\n",
    "\n",
    "# here I am assuming that the mean function is a piecewise function\n",
    "def mean2(x,hps,obj):\n",
    "    x0 = hps[5]\n",
    "\n",
    "    m1 = hps[6]\n",
    "    m2 = hps[7]\n",
    "\n",
    "    b1 = 497\n",
    "    b2 = (m1 - m2) * x0 + b1\n",
    "\n",
    "    y = np.where(x[:,0] <= x0, m1*x[:,0] + b1, m2*x[:,0] + b2)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d069fe8",
   "metadata": {},
   "source": [
    "## GP Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d0aaf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the GP Model\n",
    "init_hyperparameters = np.array( [  8.14679812e+00,  9.89985354e+02,  7.12115271e-06,  2.75031358e+00,\n",
    "  3.06519009e+00,  5.06802335e+02, -4.83379371e-02, -2.55178020e-01])\n",
    "\n",
    "my_gp1 = GPOptimizer(x_data,y_data,\n",
    "            init_hyperparameters = init_hyperparameters,  # we need enough of those for kernel, noise and prior mean functions\n",
    "            compute_device='cpu', \n",
    "            gp_kernel_function=kernel,\n",
    "            gp_kernel_function_grad=None, \n",
    "            gp_mean_function=mean2, \n",
    "            gp_mean_function_grad=None,\n",
    "            gp_noise_function=my_noise,\n",
    "            normalize_y=False,\n",
    "            sparse_mode=False,\n",
    "            gp2Scale = False,\n",
    "            store_inv=False, \n",
    "            ram_economy=False, \n",
    "            args=None)\n",
    "\n",
    "# Setting the Optimization Bounds for Hyperparameters\n",
    "bounds = np.empty((8,2))\n",
    "\n",
    "# Kernel Sq Exp\n",
    "bounds[0] = np.array([1e-5,6000.])                     # Kernel Variance\n",
    "bounds[1] = np.array([100.,1000.])                     # Kernel Lengthscale\n",
    "\n",
    "# Noise\n",
    "bounds[2] = np.array([1e-10,1.])                       # Noise Slope\n",
    "bounds[3] = np.array([2,5.])                           # Noise Power\n",
    "bounds[4] = np.array([0.,6.])                          # Noise Intercept\n",
    "# Mean\n",
    "bounds[5] = np.array([350.,750.])                      # Mean Elements Intersection\n",
    "bounds[6] = np.array([-1e-1,-1e-3])                    # Mean Slope 1\n",
    "bounds[7] = np.array([-5e-1,-1e-3])                     # Mean Slope 2\n",
    "\n",
    "#my_gp1.train(hyperparameter_bounds=bounds,max_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c4e5d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"hps: \", my_gpo.hyperparameters)\n",
    "f1 = my_gp1.posterior_mean(x_pred)[\"f(x)\"]\n",
    "v1 = my_gp1.posterior_covariance(x_pred)[\"v(x)\"]\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(x_pred[:,0],f1, color = \"blue\", linewidth = 3, label = str(data_size) + \" cells\")\n",
    "plt.scatter(x_data[:,0],y_data, color = \"black\") # Training Data\n",
    "plt.fill_between(x_pred[:,0],f1 - 2. * np.sqrt(v1), f1 + 2. * np.sqrt(v1), alpha = 0.5, color = \"grey\")\n",
    "plt.xlabel(\"cycle number\") \n",
    "plt.ylabel(\"energy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fe1c19",
   "metadata": {},
   "source": [
    "## Plotting the Prior Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa48a099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hps:  [ 8.14679812e+00  9.89985354e+02  7.12115271e-06  2.75031358e+00\n",
      "  3.06519009e+00  5.06802335e+02 -4.83379371e-02 -2.55178020e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"hps: \", my_gp1.hyperparameters)\n",
    "\n",
    "#trained_hps = np.array( [ 6.50851484e+00,  8.99467861e+02,  9.65070823e-06,  2.69545130e+00,\n",
    "#  2.97887478e+00,  4.95892427e+02, -5.14529993e-02, -2.45587221e-01])\n",
    "\n",
    "trained_hps = np.array( [  8.14679812e+00,  9.89985354e+02,  7.12115271e-06,  2.75031358e+00,\n",
    "  3.06519009e+00,  5.06802335e+02, -4.83379371e-02, -2.55178020e-01])\n",
    "\n",
    "\n",
    "#trained_prior_y1 = mean2(x_pred,my_gp1.hyperparameters,2)\n",
    "\n",
    "trained_prior_y1 = mean2(x_pred,trained_hps,2)\n",
    "\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(x_pred[:,0],trained_prior_y1, color = \"red\", linewidth = 6, label = \"Trained Prior Mean\")\n",
    "plt.scatter(x_data[:,0],y_data, color = \"black\",label = \"Synthetic Data\") # All Data\n",
    "plt.tick_params(axis='both', which='major', labelsize=label_size) # Set the font size of the tick labels on the x and y axes\n",
    "plt.xlabel(\"Cycle Number\",fontsize=label_size) \n",
    "plt.ylabel(\"Quantity of Interest\",fontsize=label_size)\n",
    "plt.legend(fontsize=label_size,frameon=False)\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig(\"/results/Methods Figures/Piecewise Model.png\", dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9748ac6f",
   "metadata": {},
   "source": [
    "# 3- Three-Element Piecewise Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7a516",
   "metadata": {},
   "source": [
    "## GP Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2132a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(x1,x2):\n",
    "    d = np.zeros((len(x1),len(x2)))\n",
    "    for i in range(x1.shape[1]):\n",
    "        d += (x1[:,i].reshape(-1, 1) - x2[:,i])**2\n",
    "    return np.sqrt(d)\n",
    "\n",
    "# For the Noise\n",
    "def s(x, my_slope, my_pow, my_intercept):\n",
    "    o = my_slope * (x**my_pow) + my_intercept\n",
    "    return o\n",
    "\n",
    "def my_noise(x,hps,obj):\n",
    "    my_slope     = hps[2]\n",
    "    my_pow       = hps[3]\n",
    "    my_intercept = hps[4]\n",
    "    \n",
    "    noise = np.identity(len(x)) * s(x,my_slope,my_pow,my_intercept)\n",
    "\n",
    "    return noise\n",
    "\n",
    "def kernel(x1,x2,hps,obj):\n",
    "    d = get_distance_matrix(x1,x2) \n",
    "    k = hps[0] * obj.squared_exponential_kernel(d,hps[1])\n",
    "    return k\n",
    "\n",
    "\n",
    "def mean3(x,hps,obj):\n",
    "    x0 = hps[5]\n",
    "    x1 = x0 + hps[6]\n",
    "\n",
    "    m1 = hps[7]\n",
    "    m2 = hps[8]\n",
    "    m3 = hps[9]\n",
    "\n",
    "    b1 = 497\n",
    "    b2 = (m1 - m2) * x0 + b1\n",
    "    b3 = (m2 - m3) * x1 + b2\n",
    "\n",
    "    y = np.where(x[:, 0] <= x0, m1*x[:, 0] + b1, \n",
    "                 np.where(x[:, 0] <= x1, m2*x[:, 0] + b2, \n",
    "                          m3*x[:, 0] + b3))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907d6a33",
   "metadata": {},
   "source": [
    "## GP Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf4cf07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the GP Model\n",
    "init_hyperparameters = np.array( [ 4.23010310e+00,  8.62740563e+02,  7.04241178e-06,  2.75391706e+00,\n",
    "  3.12227269e+00,  5.03318638e+02,  1.74737412e+02, -4.85811742e-02,\n",
    " -2.16713998e-01, -3.71356810e-01])\n",
    "\n",
    "\n",
    "my_gp2 = GPOptimizer(x_data,y_data,\n",
    "            init_hyperparameters = init_hyperparameters,  # we need enough of those for kernel, noise and prior mean functions\n",
    "            compute_device='cpu', \n",
    "            gp_kernel_function=kernel,\n",
    "            gp_kernel_function_grad=None, \n",
    "            gp_mean_function=mean3, \n",
    "            gp_mean_function_grad=None,\n",
    "            gp_noise_function=my_noise,\n",
    "            normalize_y=False,\n",
    "            sparse_mode=False,\n",
    "            gp2Scale = False,\n",
    "            store_inv=False, \n",
    "            ram_economy=False, \n",
    "            args=None)\n",
    "\n",
    "\n",
    "# Setting the Optimization Bounds for Hyperparameters\n",
    "bounds = np.empty((10,2))\n",
    "\n",
    "# Kernel Sq Exp\n",
    "bounds[0] = np.array([1e-5,6000.])                     # Kernel Variance\n",
    "bounds[1] = np.array([100.,1000.])                     # Kernel Lengthscale\n",
    "\n",
    "# Noise\n",
    "bounds[2] = np.array([1e-10,1.])                       # Noise Slope\n",
    "bounds[3] = np.array([2,5.])                           # Noise Power\n",
    "bounds[4] = np.array([0.,6.])                          # Noise Intercept\n",
    "# Mean\n",
    "bounds[5] = np.array([350.,750.])                      # Mean Elements Intersection\n",
    "bounds[6] = np.array([50.,400.])                       # Mean Elements Intersection\n",
    "bounds[7] = np.array([-1e-1,-1e-3])                    # Mean Slope 1\n",
    "bounds[8] = np.array([-4e-1,-1e-3])                    # Mean Slope 2\n",
    "bounds[9] = np.array([-4e-1,-1e-3])                    # Mean Slope 2\n",
    "\n",
    "#my_gp2.train(hyperparameter_bounds=bounds,max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5e8159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"hps: \", my_gpo.hyperparameters)\n",
    "f2 = my_gp2.posterior_mean(x_pred)[\"f(x)\"]\n",
    "v2 = my_gp2.posterior_covariance(x_pred)[\"v(x)\"]\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(x_pred[:,0],f2, color = \"blue\", linewidth = 3, label = str(data_size) + \" cells\")\n",
    "plt.scatter(x_data[:,0],y_data, color = \"black\") # Training Data\n",
    "plt.fill_between(x_pred[:,0],f2 - 2. * np.sqrt(v2), f2 + 2. * np.sqrt(v2), alpha = 0.5, color = \"grey\")\n",
    "plt.xlabel(\"cycle number\") \n",
    "plt.ylabel(\"energy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b2d00",
   "metadata": {},
   "source": [
    "## Plotting the Prior Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dad53b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hps:  [ 4.23010310e+00  8.62740563e+02  7.04241178e-06  2.75391706e+00\n",
      "  3.12227269e+00  5.03318638e+02  1.74737412e+02 -4.85811742e-02\n",
      " -2.16713998e-01 -3.71356810e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"hps: \", my_gp2.hyperparameters)\n",
    "\n",
    "trained_hps = np.array( [ 4.23010310e+00,  8.62740563e+02,  7.04241178e-06,  2.75391706e+00,\n",
    "  3.12227269e+00,  5.03318638e+02,  1.74737412e+02, -4.85811742e-02,\n",
    " -2.16713998e-01, -3.71356810e-01])\n",
    "\n",
    "trained_prior_y2 = mean3(x_pred,trained_hps,2)\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(x_pred[:,0],trained_prior_y2, color = \"red\", linewidth = 6, label = \"Trained Prior Mean\")\n",
    "plt.scatter(x_data[:,0],y_data, color = \"black\",label = \"Synthetic Data\") # All Data\n",
    "plt.tick_params(axis='both', which='major', labelsize=label_size) # Set the font size of the tick labels on the x and y axes\n",
    "plt.xlabel(\"Cycle Number\",fontsize=label_size) \n",
    "plt.ylabel(\"Quantity of Interest\",fontsize=label_size)\n",
    "plt.legend(fontsize=label_size,frameon=False)\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig(\"/results/Methods Figures/Three-Elements Piecewise Model.png\", dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d500dee0",
   "metadata": {},
   "source": [
    "# Plotting all models together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59e0c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_hps = np.array([0,0,                      # kernel - Not Needed here\n",
    "                   1.002e-05,  2.69, 3,      # Noise\n",
    "                500,-0.05,-0.2])             # Mean\n",
    "\n",
    "GT_mean_values = mean2(x_pred,GT_hps,2)\n",
    "\n",
    "my_color = np.array([102, 178, 255])/255  \n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.scatter(x_data[:,0],y_data, color =[my_color], label='Data') # Training Data\n",
    "plt.plot(x_pred[:,0],GT_mean_values, color = \"blue\", linewidth = 7, linestyle ='--', label = \"Ground Truth Mean\")\n",
    "plt.plot(x_pred[:,0],trained_prior_y_powerlaw, color = \"green\", linewidth = 7, label = \"Power Law\")\n",
    "plt.plot(x_pred[:,0],trained_prior_y1, color = \"red\", linewidth = 7, label = \"2-Element Piecewise\")\n",
    "plt.plot(x_pred[:,0],trained_prior_y2, color = \"black\", linewidth = 7, label = \"3-Element Piecewise\")\n",
    "plt.tick_params(axis='both', which='major', labelsize=label_size) # Set the font size of the tick labels on the x and y axes\n",
    "plt.xlabel(\"Cycle Number\",fontsize=label_size) \n",
    "plt.ylabel(\"QoI\",fontsize=label_size)\n",
    "plt.legend(fontsize=label_size,frameon=False)\n",
    "plt.xlim([0,1000])\n",
    "plt.ylim([250,520])\n",
    "plt.xticks([0,250,500,750,1000])\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig('/results/Methods Figures/All Mean Models.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6550dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b70572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
